{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12277617,"sourceType":"datasetVersion","datasetId":7737093}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:23:00.909183Z","iopub.execute_input":"2025-06-25T08:23:00.909942Z","iopub.status.idle":"2025-06-25T08:23:00.926873Z","shell.execute_reply.started":"2025-06-25T08:23:00.909921Z","shell.execute_reply":"2025-06-25T08:23:00.926319Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dataset/dialogues_text.txt\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip install transformers torch scikit-learn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:23:07.864953Z","iopub.execute_input":"2025-06-25T08:23:07.865234Z","iopub.status.idle":"2025-06-25T08:24:37.868877Z","shell.execute_reply.started":"2025-06-25T08:23:07.865216Z","shell.execute_reply":"2025-06-25T08:24:37.868077Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom transformers import AutoModel, AutoTokenizer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:24:50.730090Z","iopub.execute_input":"2025-06-25T08:24:50.730559Z","iopub.status.idle":"2025-06-25T08:24:50.734397Z","shell.execute_reply.started":"2025-06-25T08:24:50.730539Z","shell.execute_reply":"2025-06-25T08:24:50.733746Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"✅ Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:25:02.020128Z","iopub.execute_input":"2025-06-25T08:25:02.020906Z","iopub.status.idle":"2025-06-25T08:25:02.025271Z","shell.execute_reply.started":"2025-06-25T08:25:02.020885Z","shell.execute_reply":"2025-06-25T08:25:02.024512Z"}},"outputs":[{"name":"stdout","text":"✅ Using device: cuda\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n# 1️⃣ Read the lines\nwith open(\"/kaggle/input/dataset/dialogues_text.txt\", \"r\", encoding=\"utf-8\") as f:\n    lines = f.read().splitlines()\n\n# 2️⃣ Put lines into a DataFrame\ndata = pd.DataFrame(lines, columns=[\"raw_text\"])\n\n# 3️⃣ Remove __eou__ tags\ndata[\"cleaned_text\"] = data[\"raw_text\"].str.replace(\"__eou__\", \"\", regex=False)\ndata[\"cleaned_text\"] = data[\"raw_text\"].str.replace(\" â€™\", \"\", regex=False)\n\n\n# 4️⃣ Lowercase the text\ndata[\"cleaned_text\"] = data[\"cleaned_text\"].str.lower()\n\n# 5️⃣ Remove punctuation and special characters (keeping only letters and spaces)\ndata[\"cleaned_text\"] = data[\"cleaned_text\"].str.replace(r\"[^a-z\\s]\", \"\", regex=True)\n\n# 6️⃣ Strip any leading/trailing spaces\ndata[\"cleaned_text\"] = data[\"cleaned_text\"].str.strip()\n\n# ✅ Done! Preview the results\nprint(data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:48:41.295551Z","iopub.execute_input":"2025-06-25T08:48:41.296125Z","iopub.status.idle":"2025-06-25T08:48:41.636236Z","shell.execute_reply.started":"2025-06-25T08:48:41.296103Z","shell.execute_reply":"2025-06-25T08:48:41.635541Z"}},"outputs":[{"name":"stdout","text":"                                            raw_text  \\\n0  The kitchen stinks . __eou__ I'll throw out th...   \n1  So Dick , how about getting some coffee for to...   \n2  Are things still going badly with your housegu...   \n3  Would you mind waiting a while ? __eou__ Well ...   \n4  Are you going to the annual party ? I can give...   \n\n                                        cleaned_text  \n0  the kitchen stinks  eou ill throw out the garb...  \n1  so dick  how about getting some coffee for ton...  \n2  are things still going badly with your housegu...  \n3  would you mind waiting a while  eou well  how ...  \n4  are you going to the annual party  i can give ...  \n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Replace this with your actual data load\n# data = pd.read_csv(\"your_file.csv\") \n# Must have data[\"cleaned_text\"]\n\nmodel_name = \"sentence-transformers/all-mpnet-base-v2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nhf_model = AutoModel.from_pretrained(model_name).to(device)\n\ndef embed(texts, batch_size=32):\n    embeddings = []\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i + batch_size]\n        enc = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=128).to(device)\n        with torch.no_grad():\n            outputs = hf_model(**enc)\n            emb = outputs.last_hidden_state.mean(dim=1)\n        embeddings.append(emb.cpu().numpy())\n    return np.vstack(embeddings)\n\nembedding_array = embed(data[\"cleaned_text\"].tolist())\nembedding_array.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:48:47.330667Z","iopub.execute_input":"2025-06-25T08:48:47.331285Z","iopub.status.idle":"2025-06-25T08:50:31.493931Z","shell.execute_reply.started":"2025-06-25T08:48:47.331264Z","shell.execute_reply":"2025-06-25T08:50:31.493140Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(13118, 768)"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"embedding_dim = embedding_array.shape[1]\nlatent_dim = 64  # Adjust if needed\n\nclass Autoencoder(nn.Module):\n    def __init__(self, input_dim, latent_dim=64):\n        super(Autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, latent_dim),\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, 256),\n            nn.ReLU(),\n            nn.Linear(256, input_dim),\n        )\n    def forward(self, x):\n        latent = self.encoder(x)\n        recon = self.decoder(latent)\n        return recon, latent\n\nautoencoder = Autoencoder(embedding_dim, latent_dim).to(device)\n\nembedding_tensor = torch.tensor(embedding_array, dtype=torch.float32).to(device)\ndataloader = DataLoader(TensorDataset(embedding_tensor), batch_size=32, shuffle=True)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)\n\n# Training Loop\nfor epoch in range(30):  # Adjust epochs if needed\n    total_loss = 0\n    for batch in dataloader:\n        batch_data = batch[0]\n        recon, latent = autoencoder(batch_data)\n        loss = criterion(recon, batch_data)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    if (epoch + 1) % 5 == 0:\n        print(f\"✅ Epoch [{epoch + 1}/30] - Reconstruction Loss: {total_loss / len(dataloader):.4f}\")\n\n# Final Latent Embeddings\nwith torch.no_grad():\n    latent_embeddings = autoencoder.encoder(embedding_tensor).cpu().numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:44:34.579722Z","iopub.execute_input":"2025-06-25T08:44:34.580238Z","iopub.status.idle":"2025-06-25T08:44:57.394067Z","shell.execute_reply.started":"2025-06-25T08:44:34.580215Z","shell.execute_reply":"2025-06-25T08:44:57.393360Z"}},"outputs":[{"name":"stdout","text":"✅ Epoch [5/30] - Reconstruction Loss: 0.0031\n✅ Epoch [10/30] - Reconstruction Loss: 0.0029\n✅ Epoch [15/30] - Reconstruction Loss: 0.0028\n✅ Epoch [20/30] - Reconstruction Loss: 0.0028\n✅ Epoch [25/30] - Reconstruction Loss: 0.0027\n✅ Epoch [30/30] - Reconstruction Loss: 0.0027\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\nbest_score = -1\nbest_n_clusters = None\nbest_labels = None\n\n# Try n_clusters from 5 to 10\nfor n_clusters in range(5, 15):\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    labels = kmeans.fit_predict(latent_embeddings)\n    sil_score = silhouette_score(latent_embeddings, labels)\n    \n    \n    if sil_score > best_score:\n        best_score = sil_score\n        best_n_clusters = n_clusters\n        best_labels = labels\n\n# Final results\ndata[\"cluster\"] = best_labels\nprint(f\"✅ Best n_clusters: {best_n_clusters}, with silhouette_score = {best_score:.4f}\")\n\n# Save Results\ndata[\"cluster\"] = labels\ndata.to_csv(\"dec_clusters.csv\", index=False)\nprint(\"✅ Done! Results saved to dec_clusters.csv.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:45:55.150445Z","iopub.execute_input":"2025-06-25T08:45:55.150746Z","iopub.status.idle":"2025-06-25T08:46:26.765475Z","shell.execute_reply.started":"2025-06-25T08:45:55.150727Z","shell.execute_reply":"2025-06-25T08:46:26.764637Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ Best n_clusters: 10, with silhouette_score = 0.0357\n✅ Done! Results saved to dec_clusters.csv.\n","output_type":"stream"}],"execution_count":27}]}